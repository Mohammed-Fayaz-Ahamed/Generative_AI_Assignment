{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "t0hGDTUPYBrX"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BART-Large-MNLI model\n",
        "model = transformers.AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-mnli\")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")"
      ],
      "metadata": {
        "id": "BR-dOqHfYOsq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt, max_new_tokens=50):  # Set max_new_tokens to 50 (adjust as needed)\n",
        "  \"\"\"Generates a response using the BART-Large-MNLI model.\"\"\"\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "  outputs = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
        "  response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  return response"
      ],
      "metadata": {
        "id": "gDZGFR4XYUFR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greet_user():\n",
        "  \"\"\"Greets the user based on the current time.\"\"\"\n",
        "  hour = datetime.datetime.now().hour\n",
        "  if hour < 12:\n",
        "    return \"Good morning!\"\n",
        "  elif hour < 17:\n",
        "    return \"Good afternoon!\"\n",
        "  else:\n",
        "    return \"Good evening!\""
      ],
      "metadata": {
        "id": "1GdQfbVlYXZ5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tell_time():\n",
        "  \"\"\"Provides the current time.\"\"\"\n",
        "  time_str = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
        "  return f\"The current time is {time_str}.\""
      ],
      "metadata": {
        "id": "GBtan_vrYaVJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == \"hi\" or user_input.lower() == \"hello\":\n",
        "      print(greet_user())\n",
        "    elif user_input.lower() == \"what time is it\":\n",
        "      print(tell_time())\n",
        "    elif user_input.lower() == \"tell me a joke\":\n",
        "      print(generate_response(\"Tell me a joke.\"))\n",
        "    else:\n",
        "      print(generate_response(user_input))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NX7KBL9YdLJ",
        "outputId": "fab5f1ea-8aa5-4453-a497-fb8ba0943f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: hello\n",
            "Good morning!\n",
            "You: what time is it\n",
            "The current time is 05:48:39.\n",
            "You: tell me a joke\n",
            "\n"
          ]
        }
      ]
    }
  ]
}